{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89vwfFVfQUBo"
      },
      "outputs": [],
      "source": [
        "!pip -qq install super-gradients==3.6.0 pytorch-quantization==2.1.2 --extra-index-url https://pypi.ngc.nvidia.com"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients import Trainer\n",
        "import pprint\n",
        "\n",
        "experiment_name = \"cifar100_ptq_qat_classification\"\n",
        "\n",
        "CHECKPOINT_DIR = 'checkpoints'\n",
        "trainer = Trainer(experiment_name=experiment_name, ckpt_root_dir=CHECKPOINT_DIR)"
      ],
      "metadata": {
        "id": "WUUdDLKDUt-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import dataloaders\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define data augmentation transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create train and validation datasets\n",
        "train_dataset = datasets.CIFAR100(root=\"./data\", train=True, download=True, transform=train_transform)\n",
        "valid_dataset = datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=valid_transform)\n",
        "\n",
        "# Create train and validation dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, persistent_workers=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=2, persistent_workers=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9Oo1fu4i61H",
        "outputId": "e0bdfea9-82b4-4269-e582-acedca8f50a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def show(images, labels, classes, rows=6, columns=5):\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "  for i in range(1, columns * rows + 1):\n",
        "      fig.add_subplot(rows, columns, i)\n",
        "      plt.imshow(images[i-1].permute(1, 2, 0).clamp(0, 1))\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "      plt.title(f\"{classes[labels[i-1]]}\")"
      ],
      "metadata": {
        "id": "pgKYQqluVHXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vis_images_train, vis_labels_train = next(iter(train_dataloader))\n",
        "show(vis_images_train, vis_labels_train, classes=train_dataloader.dataset.classes)\n",
        "\n",
        "print(vis_images_train.shape, vis_labels_train.shape)"
      ],
      "metadata": {
        "id": "-23lZr_wVQUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import models\n",
        "from super_gradients.common.object_names import Models\n",
        "\n",
        "model_type = 'mobilenet'\n",
        "\n",
        "if model_type == 'resnet':\n",
        "  model = models.get(model_name=Models.RESNET50, num_classes=100, pretrained_weights=\"imagenet\")\n",
        "elif model_type == 'efficientnet':\n",
        "  model = models.get(model_name=Models.EFFICIENTNET_B0, num_classes=100, pretrained_weights=\"imagenet\")\n",
        "elif model_type == 'mobilenet':\n",
        "  model = models.get(model_name=Models.MOBILENET_V3_SMALL, num_classes=100, pretrained_weights=\"imagenet\")\n",
        "else:\n",
        "  raise ValueError(f\"Unknown model type: {model_type}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FafcB6d4VXqR",
        "outputId": "9e67b70b-3fb4-460d-fd57-173a08026796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://sghub.deci.ai/models/mobilenet_v3_small_imagenet.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small_imagenet.pth\n",
            " 77%|███████▋  | 22.4M/29.3M [00:03<00:00, 14.0MB/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import Trainer\n",
        "from super_gradients.training import training_hyperparams\n",
        "\n",
        "# you can see more recipes in super_gradients/recipes\n",
        "training_params =  training_hyperparams.get(\"training_hyperparams/cifar10_resnet_train_params\")"
      ],
      "metadata": {
        "id": "m0RA3nGeV210"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(\"Training parameters\")\n",
        "pprint.pprint(training_params)"
      ],
      "metadata": {
        "id": "us3e681SWKzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_params[\"initial_lr\"] = 0.1\n",
        "training_params[\"max_epochs\"] = 1\n",
        "training_params[\"lr_updates\"] = [10, 25, 45]\n",
        "training_params[\"lr_warmup_epochs\"] = 5\n",
        "training_params[\"warmup_initial_lr\"] = 0.01\n",
        "training_params[\"save_ckpt_epoch_list\"] = [1, 5, 10]"
      ],
      "metadata": {
        "id": "C1SB2ye_WOV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train(model=model,\n",
        "              training_params=training_params,\n",
        "              train_loader=train_dataloader,\n",
        "              valid_loader=valid_dataloader)"
      ],
      "metadata": {
        "id": "aZnPo2C3WT3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "from torch import nn\n",
        "from super_gradients.training.utils.quantization.calibrator import QuantizationCalibrator\n",
        "from super_gradients.training.utils.quantization.export import export_quantized_module_to_onnx\n",
        "from super_gradients.training.utils.quantization.selective_quantization_utils import SelectiveQuantizer\n",
        "from super_gradients.modules.repvgg_block import fuse_repvgg_blocks_residual_branches\n",
        "\n",
        "def load_checkpoint(model, ckpt_file):\n",
        "  checkpoint = torch.load(ckpt_file, map_location=\"cpu\")\n",
        "  ckpt_key = \"ema_net\" if \"ema_net\" in checkpoint else \"net\"\n",
        "  state_dict = checkpoint[ckpt_key]\n",
        "  model.load_state_dict(state_dict)\n",
        "\n",
        "def validate_model(model, dataloader, training_hyperparams):\n",
        "  trainer = Trainer(experiment_name=experiment_name, ckpt_root_dir=CHECKPOINT_DIR)\n",
        "\n",
        "  valid_metrics_dict = trainer.test(model=model, test_loader=dataloader, test_metrics_list=training_hyperparams.get(\"valid_metrics_list\"))\n",
        "\n",
        "  results = [\"Validate Results\"]\n",
        "  results += [f\"\\t- {metric:4}: {value:.3f}\" for metric, value in valid_metrics_dict.items()]\n",
        "\n",
        "  res_string = \"\\r\\n\".join(results)\n",
        "\n",
        "  print(res_string, file=sys.stderr)\n",
        "\n",
        "  return valid_metrics_dict\n",
        "\n",
        "print(os.path.join(trainer.checkpoints_dir_path, \"ckpt_best.pth\"))\n",
        "load_checkpoint(model, os.path.join(trainer.checkpoints_dir_path, \"ckpt_best.pth\"))\n",
        "validate_model(model, valid_dataloader, training_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdnATySLafH9",
        "outputId": "da1d439b-8ef6-4fd3-91bf-a86b5a50c7fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoints/cifar100_ptq_qat_classification/RUN_20240310_110023_818008/ckpt_best.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing:  96%|█████████▌| 150/157 [00:07<00:00, 21.55it/s]"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 0.7960000038146973, 'Top5': 0.9625999927520752}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTesting:  97%|█████████▋| 153/157 [00:07<00:00, 20.70it/s]\rTesting:  99%|█████████▉| 156/157 [00:07<00:00, 21.82it/s]\rTesting: 100%|██████████| 157/157 [00:07<00:00, 21.08it/s]\n",
            "Validate Results\r\n",
            "\t- Accuracy: 0.796\r\n",
            "\t- Top5: 0.963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "POST TRAINING QUANTIZATION (PTQ)"
      ],
      "metadata": {
        "id": "klIoQagcbFMM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taJVOpbq0cDO",
        "ExecuteTime": {
          "end_time": "2023-11-07T09:33:20.712650300Z",
          "start_time": "2023-11-07T09:33:20.659849100Z"
        }
      },
      "outputs": [],
      "source": [
        "def quantize_and_calibrate(\n",
        "    model: nn.Module,\n",
        "    calibration_dataloader,\n",
        "    num_calib_batches=16,             # number of batches to use for calibration\n",
        "    method_w=\"max\",                   # calibrator type for weights, acceptable types are [\"max\", \"histogram\"]\n",
        "    method_i=\"histogram\",             # calibrator type for inputs, acceptable types are [\"max\", \"histogram\"]\n",
        "    calibration_method=\"percentile\",  # calibration method for all \"histogram\" calibrators, acceptable types are [\"percentile\", \"entropy\", mse\"], \"max\" calibrators are not affected\n",
        "    percentile=99.99,                 # percentile for all histogram calibrators with method \"percentile\", other calibrators are not affected\n",
        "    per_channel=True,                 # per-channel quantization of weights, activations stay per-tensor by default\n",
        "    learn_amax=False,                 # enable learnable amax in all TensorQuantizers using straight-through estimator\n",
        "    skip_modules=None,                # optional list of module names (strings) to skip from quantization\n",
        "    verbose=False,                    # if calibrator should be verbose\n",
        "):\n",
        "    model.eval()\n",
        "\n",
        "    q_util = SelectiveQuantizer(\n",
        "        default_quant_modules_calibrator_weights=method_w,\n",
        "        default_quant_modules_calibrator_inputs=method_i,\n",
        "        default_per_channel_quant_weights=per_channel,\n",
        "        default_learn_amax=learn_amax,\n",
        "        verbose=verbose\n",
        "    )\n",
        "\n",
        "    if skip_modules is not None:\n",
        "        q_util.register_skip_quantization(layer_names=set(skip_modules))\n",
        "\n",
        "    calibrator = QuantizationCalibrator(verbose=verbose, torch_hist=True)\n",
        "\n",
        "    # RepVGG and QARepVGG can be quantized only in the fused form\n",
        "    fuse_repvgg_blocks_residual_branches(model)\n",
        "    q_util.quantize_module(model)\n",
        "\n",
        "    calibrator.calibrate_model(\n",
        "        model,\n",
        "        method=calibration_method,\n",
        "        calib_data_loader=calibration_dataloader,\n",
        "        num_calib_batches=num_calib_batches,\n",
        "        percentile=percentile,\n",
        "    )\n",
        "\n",
        "    model.train()\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_checkpoint(model, os.path.join(trainer.checkpoints_dir_path, \"ckpt_best.pth\"))\n",
        "ptq_model = quantize_and_calibrate(copy.deepcopy(model),\n",
        "                                    train_dataloader,\n",
        "                                    num_calib_batches=4,\n",
        "                                    method_w=\"max\",\n",
        "                                    method_i=\"max\",\n",
        "                                    calibration_method=\"percentile\",\n",
        "                                    percentile=99.99,\n",
        "                                    per_channel=True,\n",
        "                                    learn_amax=False,\n",
        "                                    skip_modules=None,\n",
        "                                    verbose=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlZsMHJcaufl",
        "outputId": "c24d76d5-b4ed-48f3-cb02-ccb4702e9a16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate_model(ptq_model, valid_dataloader, training_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsOU56riazox",
        "outputId": "d6bb2de8-2c0e-4ca3-92b7-33a15863d54b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing:  97%|█████████▋| 153/157 [00:12<00:00, 12.55it/s]"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 0.6363999843597412, 'Top5': 0.8851000070571899}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Float vs Quantized Model Accuracy\n",
        "\n",
        "1. ResNet50: top1 (), top5 ()\n",
        "2. EfficientNet-B0: top1 (), top5 ()\n",
        "3. MobileNet-V3: top1 (), top5 ()"
      ],
      "metadata": {
        "id": "Iu-vBUJKUhTC"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}